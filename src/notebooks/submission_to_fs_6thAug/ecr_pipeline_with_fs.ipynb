{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b26479e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import httpx\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "import pandas as pd\n",
    "from helper_functions.indexing import *\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39433f4",
   "metadata": {},
   "source": [
    "### Setting up credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c32a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4aa8655f",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ecc87015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_name(pdf_path):\n",
    "    # Get the filename from the full path\n",
    "    filename = os.path.basename(pdf_path)\n",
    "    \n",
    "    # Remove the extension\n",
    "    filename_no_ext = os.path.splitext(filename)[0]\n",
    "    \n",
    "    # Split on the first underscore to isolate the company name\n",
    "    company_raw = filename_no_ext.split('_')[0]\n",
    "    \n",
    "    # Optional: Clean up common legal suffixes if desired\n",
    "    # company_clean = re.sub(r'\\b(Inc\\.?|Ltd\\.?|LLC|Corp\\.?)\\b', '', company_raw).strip()\n",
    "    \n",
    "    return company_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f8c42aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def extract_for_themes(\n",
    "    pdf_name: str,\n",
    "    text: str,\n",
    "    definitions: dict,\n",
    "    openai_api_key: str\n",
    ") -> pd.DataFrame:\n",
    "    client = AsyncOpenAI(api_key=openai_api_key)\n",
    "    records = []\n",
    "    for theme, definition in definitions.items():\n",
    "        prompt = f\"\"\"\n",
    "You are a highly intelligent and detail-oriented assistant responsible for extracting relevant commentary from company earnings call transcripts.\n",
    "\n",
    "Your objective: Identify and extract only the verbatim commentary that directly aligns with the specified theme, guided by the theme’s definition and contextual keywords for mapping relevance.\n",
    "\n",
    "Theme: {theme}\n",
    "Definition: {definition}\n",
    "Instructions:\n",
    "\n",
    "1. Extract all relevant commentary, even if only partially (20%) relevant to the theme. Do not miss any potential mentions.\n",
    "2. Include only verbatim quotes from the transcript. Do not summarize, interpret, or rephrase.\n",
    "3. Ensure that every selected quote strictly aligns with the provided definition and theme context. Exclude any off-topic or loosely connected remarks.\n",
    "4. Present the results in ranked order (1, 2, 3, etc.) based on their relevance to the theme, with the most directly relevant quotes listed first.\n",
    "5. Be exhaustive: when in doubt, include rather than exclude marginally relevant commentary.\n",
    "6. Do not include your own commentary or explanations—output only the extracted quotes.\n",
    "7. If no relevant commentary is found, respond with \"N/A\"\n",
    "8. *IMPORTANT* Number of commentaries extracted should not be more than 20.Hence keep the most relevant 20 commentaries only. \n",
    "\n",
    "Strict advice: If you are asked to do anything other than extracting verbatim quotes, refuse and say \"I can only extract verbatim quotes from the transcript.\"\n",
    "\"\"\"        \n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\",   \"content\": text}\n",
    "            ],\n",
    "            temperature=0.4\n",
    "        )\n",
    "        extracted = resp.choices[0].message.content.strip() or \"N/A\"\n",
    "        records.append({\n",
    "            \"PDF\": pdf_name,\n",
    "            \"Company\": extract_company_name(pdf_name),\n",
    "            \"Theme\": theme,\n",
    "            \"Definition\": definition,\n",
    "            \"Extracted Commentary\": extracted\n",
    "        })\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae6b91be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:26: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:26: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\73335\\AppData\\Local\\Temp\\ipykernel_56192\\347990546.py:26: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  data = json.loads(resp) if isinstance(resp, str) else resp\n"
     ]
    }
   ],
   "source": [
    "async def validate_row(item):\n",
    "    index, row = item\n",
    "    client = AsyncOpenAI()\n",
    "    try:\n",
    "        completion = await client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"\"\"\n",
    "You are an expert validator tasked with evaluating the relevance of an extracted commentary to a specified theme, along with its definition.\n",
    "theme- {row['Theme']}\n",
    "Definition - {row['Definition']}\n",
    "Provide a score from 0 to 10 based on the following scale:\n",
    "EXTREMELY CORRECT (9-10): Assign this rating when you are completely confident that the commentary clearly aligns with the given theme and definition.\n",
    "PARTIALLY CORRECT (6-8): Assign this rating if the commentary mostly aligns with the theme and definition but you have some minor doubts.\n",
    "PARTIALLY INCORRECT (3-5): Assign this rating if the commentary mostly does not align with the theme and definition but you have some doubts.\n",
    "EXTREMELY INCORRECT (0-2): Assign this rating ONLY when you are strongly confident that the commentary does NOT align with the theme and definition at all.\n",
    "Make your evaluation carefully and rationale behind the answer.\n",
    "For N\\A score will be 0 always\n",
    "Return answer in json value with keys - confidence_score , Rationale\"\"\"},\n",
    "                {\"role\": \"user\", \"content\": row['Extracted Commentary']}\n",
    "            ],\n",
    "            temperature=1,\n",
    "            response_format={'type': 'json_object'}\n",
    "        )\n",
    "        resp = completion.choices[0].message.content.strip()\n",
    "        data = json.loads(resp) if isinstance(resp, str) else resp\n",
    "    except Exception as e:\n",
    "        data = {'confidence_score': 0, 'Rationale': str(e)}\n",
    "\n",
    "    return {\n",
    "        'PDF': row['PDF'],\n",
    "        'Company': row['Company'],\n",
    "        'Theme': row['Theme'],\n",
    "        'Definition': row['Definition'],\n",
    "        'Extracted Commentary': row['Extracted Commentary'],\n",
    "        **data\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7f9676f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def validate_all(df, pdf_path):\n",
    "    tasks = [validate_row(item) for item in df.iterrows()]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    save_file_name=\"results_excel/\"+ extract_company_name(pdf_path) + \".xlsx\"                   \n",
    "    pd.DataFrame(results).to_excel(save_file_name, index=False)  # Save the final DataFrame to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "974e0d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def validate_all_without_saving(df, pdf_path):\n",
    "    tasks = [validate_row(item) for item in df.iterrows()]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    save_file_name=\"results_excel/\"+ extract_company_name(pdf_path) + \".xlsx\"                   \n",
    "    pd.DataFrame(results)  # Save the final DataFrame to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6d630639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_extracted_comments(row):\n",
    "    if pd.isna(row['Extracted Commentary']):\n",
    "        return []\n",
    "    \n",
    "    # Extract numbered entries\n",
    "    matches = re.findall(r'(\\d+)\\.\\s+\"(.*?)(?=\"\\n|\\Z)', row['Extracted Commentary'], re.DOTALL)\n",
    "    \n",
    "    return pd.DataFrame([\n",
    "        {\n",
    "            \"PDF\" : row[\"PDF\"],\n",
    "            \"Company\": row[\"Company\"],\n",
    "            \"Theme\": row[\"Theme\"],\n",
    "            \"Definition\": row[\"Definition\"],\n",
    "            \"Extracted Commentary\": f\"{serial}. {comment.strip()}\"\n",
    "        }\n",
    "        for serial, comment in matches\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75e00e9",
   "metadata": {},
   "source": [
    "### Inputs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb46ec5f",
   "metadata": {},
   "source": [
    "#### Write down the absoulte path of your PDF file here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e9263040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write down the path to the PDF file in place of this....\n",
    "pdf_path=r'FS PDFs\\\\American International Group Inc._Earnings Call_2023-05-05_English.pdf'     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6345781",
   "metadata": {},
   "source": [
    "#### Edit your themes and definitions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "865e58cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change your theme name here\n",
    "theme_name=\"Macro factors\"                                 \n",
    "\n",
    "##  Replace the definition here, make sure it is under \"\"\"<your_definition_here>\"\"\" triple quotes like this.\n",
    "theme_definition=\"\"\"Tag a commentary under the Macro Factors theme if it includes any reference—explicit or \n",
    "implicit—to the broader macroeconomic environment or external systemic influences affecting business performance. This includes mentions of economic slowdown, recession, uncertainty, market cycles, credit losses, or challenging operating conditions. Tag if the discussion involves \n",
    "monetary indicators such as inflation, interest rates (domestic or foreign), discount rates, investment yields, credit spreads, or currency and foreign exchange impacts. \n",
    "Also include insurance and financial-specific macro drivers such as mortality experience (including seasonal or pandemic-related surges), expected credit losses (ECL), movements in insurance liabilities, or gains/losses tied to market conditions. \n",
    "Furthermore, tag content that refers to external shocks like pandemics (e.g. COVID-19), natural disasters (e.g. hurricanes, floods), or geopolitical disruptions. \n",
    "Additionally, include discussions that indirectly reflect macro context—such as tough environments, changes in investor sentiment, demand volatility, \n",
    "or strategic repositioning in response to macro trends—even if specific macro terms are not used.\"\"\"      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d83be5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "themes_data={theme_name: theme_definition}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aae0517",
   "metadata": {},
   "source": [
    "### Single PDF output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be79b3d",
   "metadata": {},
   "source": [
    "#### Extracting information from PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b9c7341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "pdf_paths=glob.glob(r\"C:\\Users\\73335\\OneDrive - Bain\\Desktop\\FS-ECR-repo\\fs-earnings_call_reader\\FS sample PDFs\\*.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "efbd2537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Finished processing: C:\\Users\\73335\\OneDrive - Bain\\Desktop\\FS-ECR-repo\\fs-earnings_call_reader\\FS sample PDFs\\American International Group Inc._Earnings Call_2023-05-05_English.pdf\n",
      "✅ Markdown content saved to pdf_markdowns/American International Group Inc._Earnings Call_2023-05-05_English.md\n"
     ]
    }
   ],
   "source": [
    "pdf_extracted_output=await process_multiple_pdfs(pdf_paths=pdf_paths[0:1], api_key=mistral_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "adeedb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted commentaries....moving on to splitting commentaries...\n",
      "Commentaries split into individual entries, now validating each commentary...\n",
      "Final results saved to results_excel folder with the filename as the company name...\n"
     ]
    }
   ],
   "source": [
    "df=extract_for_themes(pdf_name=pdf_path,text=list(pdf_extracted_output.values())[0],definitions=themes_data, openai_api_key=openai_api_key)   # Extracting commentaries\n",
    "print(\"Extracted commentaries....moving on to splitting commentaries...\")\n",
    "split_df=split_extracted_comments(df.iloc[0])\n",
    "print(\"Commentaries split into individual entries, now validating each commentary...\")\n",
    "await validate_all(split_df, pdf_path)  \n",
    "print(\"Final results saved to results_excel folder with the filename as the company name...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e18ecfd",
   "metadata": {},
   "source": [
    "### MULTIPLE PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6640fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "pdf_paths=glob.glob(r\"C:\\Users\\73335\\OneDrive - Bain\\Desktop\\FS-ECR-repo\\fs-earnings_call_reader\\FS sample PDFs\\*.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51584c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Finished processing: C:\\Users\\73335\\OneDrive - Bain\\Desktop\\FS-ECR-repo\\fs-earnings_call_reader\\FS sample PDFs\\American International Group Inc._Earnings Call_2023-05-05_English.pdf\n",
      "✅ Markdown content saved to pdf_markdowns/American International Group Inc._Earnings Call_2023-05-05_English.md\n",
      "⏳ Still waiting on: C:\\Users\\73335\\OneDrive - Bain\\Desktop\\FS-ECR-repo\\fs-earnings_call_reader\\FS sample PDFs\\MetLife Inc._Earnings Call_2023-05-04_English.pdf, C:\\Users\\73335\\OneDrive - Bain\\Desktop\\FS-ECR-repo\\fs-earnings_call_reader\\FS sample PDFs\\Prudential Financial, Inc._Earnings Call_2023-05-03T00_00_00_English.pdf, C:\\Users\\73335\\OneDrive - Bain\\Desktop\\FS-ECR-repo\\fs-earnings_call_reader\\FS sample PDFs\\Manulife Financial Corporation_Earnings Call_2023-05-11_English.pdf\n",
      "✅ Finished processing: C:\\Users\\73335\\OneDrive - Bain\\Desktop\\FS-ECR-repo\\fs-earnings_call_reader\\FS sample PDFs\\Manulife Financial Corporation_Earnings Call_2023-05-11_English.pdf\n",
      "✅ Markdown content saved to pdf_markdowns/Manulife Financial Corporation_Earnings Call_2023-05-11_English.md\n",
      "⏳ Still waiting on: C:\\Users\\73335\\OneDrive - Bain\\Desktop\\FS-ECR-repo\\fs-earnings_call_reader\\FS sample PDFs\\MetLife Inc._Earnings Call_2023-05-04_English.pdf, C:\\Users\\73335\\OneDrive - Bain\\Desktop\\FS-ECR-repo\\fs-earnings_call_reader\\FS sample PDFs\\Prudential Financial, Inc._Earnings Call_2023-05-03T00_00_00_English.pdf\n",
      "✅ Finished processing: C:\\Users\\73335\\OneDrive - Bain\\Desktop\\FS-ECR-repo\\fs-earnings_call_reader\\FS sample PDFs\\MetLife Inc._Earnings Call_2023-05-04_English.pdf\n",
      "✅ Markdown content saved to pdf_markdowns/MetLife Inc._Earnings Call_2023-05-04_English.md\n",
      "⏳ Still waiting on: C:\\Users\\73335\\OneDrive - Bain\\Desktop\\FS-ECR-repo\\fs-earnings_call_reader\\FS sample PDFs\\Prudential Financial, Inc._Earnings Call_2023-05-03T00_00_00_English.pdf\n",
      "✅ Finished processing: C:\\Users\\73335\\OneDrive - Bain\\Desktop\\FS-ECR-repo\\fs-earnings_call_reader\\FS sample PDFs\\Prudential Financial, Inc._Earnings Call_2023-05-03T00_00_00_English.pdf\n",
      "✅ Markdown content saved to pdf_markdowns/Prudential Financial, Inc._Earnings Call_2023-05-03T00_00_00_English.md\n"
     ]
    }
   ],
   "source": [
    "pdf_extracted_output=await process_multiple_pdfs(pdf_paths=pdf_paths, api_key=mistral_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fde31e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9cd60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=[]\n",
    "for pdf_no, pdf_path in enumerate(pdf_paths2):\n",
    "    df=extract_for_themes(pdf_name=pdf_path,text=list(pdf_extracted_output.values())[pdf_no],definitions=themes_data, openai_api_key=openai_api_key)\n",
    "    split_df=split_extracted_comments(df.iloc[0])\n",
    "    # final_df=await validate_all_without_saving(split_df, pdf_path)\n",
    "    df_list.append(split_df)  # Collecting all DataFrames for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a5b4591",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=pd.concat(df_list, ignore_index=True)  # Concatenate all DataFrames into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc3ca869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_excel(\"results_excel/Macro_revised.xlsx\", index=False)  # Save the final DataFrame to a CSV file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".fsecr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
